{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c8fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import sklearn \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "\n",
    "import IvysaurusModel\n",
    "import FileHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1c5f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/isobel/Desktop/DUNE/Ivysaurus/files/ivysaurus_0_nutau.root', '/Users/isobel/Desktop/DUNE/Ivysaurus/files/ivysaurus_0_nue.root', '/Users/isobel/Desktop/DUNE/Ivysaurus/files/ivysaurus_1_nue.root', '/Users/isobel/Desktop/DUNE/Ivysaurus/files/ivysaurus_0_nu.root', '/Users/isobel/Desktop/DUNE/Ivysaurus/files/ivysaurus_1_nu.root']\n"
     ]
    }
   ],
   "source": [
    "fileNames = glob.glob('/Users/isobel/Desktop/DUNE/Ivysaurus/files/ivysaurus_*.root')\n",
    "trainVarFile = '/Users/isobel/Desktop/DUNE/Ivysaurus/files/trainVarArrays.npz'\n",
    "print(fileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72df6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3089e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll put some hyperparameters...\n",
    "\n",
    "dimensions = 12\n",
    "nClasses = 6\n",
    "nTrackVars = 6 # nTrackChildren, nShowerChildren, nGrandChildren, trackLength, trackWobble, trackScore\n",
    "         \n",
    "ntrain = 584248\n",
    "ntest  = 64917\n",
    "\n",
    "nEpochs = 10\n",
    "batchSize = 64\n",
    "learningRate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90ff8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5c3486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we'll get our information...\n",
    "\n",
    "useExistingVariableFile = True\n",
    "\n",
    "if not (useExistingVariableFile):\n",
    "\n",
    "    # Read tree\n",
    "    startGridU, startGridV, startGridW, endGridU, endGridV, endGridW, trackVars, y = FileHelper.readTree(fileNames, dimensions, nClasses)\n",
    "\n",
    "    print(startGridU.shape)\n",
    "    print(trackVars.shape)\n",
    "    \n",
    "    # This should shuffle things so that the indicies are still linked\n",
    "    startGridU, startGridV, startGridW, endGridU, endGridV, endGridW, trackVars, y = sklearn.utils.shuffle(startGridU, startGridV, startGridW, endGridU, endGridV, endGridW, trackVars, y)\n",
    "\n",
    "    startGridU_train = startGridU[:ntrain]\n",
    "    startGridV_train = startGridV[:ntrain]\n",
    "    startGridW_train = startGridW[:ntrain]\n",
    "\n",
    "    startGridU_test = startGridU[ntrain:(ntrain + ntest)]\n",
    "    startGridV_test = startGridV[ntrain:(ntrain + ntest)]\n",
    "    startGridW_test = startGridW[ntrain:(ntrain + ntest)]\n",
    "\n",
    "    endGridU_train = endGridU[:ntrain]\n",
    "    endGridV_train = endGridV[:ntrain]\n",
    "    endGridW_train = endGridW[:ntrain]\n",
    "\n",
    "    endGridU_test = endGridU[ntrain:(ntrain + ntest)]\n",
    "    endGridV_test = endGridV[ntrain:(ntrain + ntest)]\n",
    "    endGridW_test = endGridW[ntrain:(ntrain + ntest)]\n",
    "    \n",
    "    trackVars_train = trackVars[:ntrain]\n",
    "    trackVars_test = trackVars[ntrain:(ntrain + ntest)]\n",
    "\n",
    "    y_train = y[:ntrain]\n",
    "    y_test = y[ntrain:(ntrain + ntest)]\n",
    "    \n",
    "    np.savez(trainVarFile, startGridU_train=startGridU_train, startGridV_train=startGridV_train, startGridW_train=startGridW_train, startGridU_test=startGridU_test, startGridV_test=startGridV_test, startGridW_test=startGridW_test, endGridU_train=endGridU_train, endGridV_train=endGridV_train, endGridW_train=endGridW_train, trackVars_train=trackVars_train, endGridU_test=endGridU_test, endGridV_test=endGridV_test, endGridW_test=endGridW_test, trackVars_test=trackVars_test, y_train=y_train, y_test=y_test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a408ba3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5954b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de1b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b715b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5098ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (useExistingVariableFile):\n",
    "    data = np.load(trainVarFile)\n",
    "    \n",
    "    startGridU_train = data['startGridU_train']\n",
    "    startGridV_train = data['startGridV_train']\n",
    "    startGridW_train = data['startGridW_train']\n",
    "    \n",
    "    startGridU_test = data['startGridU_test']\n",
    "    startGridV_test = data['startGridV_test'] \n",
    "    startGridW_test = data['startGridW_test']\n",
    "    \n",
    "    endGridU_train = data['endGridU_train']\n",
    "    endGridV_train = data['endGridV_train']\n",
    "    endGridW_train = data['endGridW_train']\n",
    "    \n",
    "    endGridU_test = data['endGridU_test']\n",
    "    endGridV_test = data['endGridV_test']\n",
    "    endGridW_test = data['endGridW_test']\n",
    "    \n",
    "    trackVars_train = data['trackVars_train']\n",
    "    trackVars_test = data['trackVars_test']\n",
    "    \n",
    "    y_train = data['y_train']\n",
    "    y_test = data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a57a004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startGridU_train:  (584248, 12, 12)\n",
      "startGridV_train:  (584248, 12, 12)\n",
      "startGridW_train:  (584248, 12, 12)\n",
      "startGridU_test:  (64917, 12, 12)\n",
      "startGridV_test:  (64917, 12, 12)\n",
      "startGridW_test:  (64917, 12, 12)\n",
      "endGridU_train:  (584248, 12, 12)\n",
      "endGridV_train:  (584248, 12, 12)\n",
      "endGridW_train:  (584248, 12, 12)\n",
      "endGridU_test:  (64917, 12, 12)\n",
      "endGridV_test:  (64917, 12, 12)\n",
      "endGridW_test:  (64917, 12, 12)\n",
      "trackVars_train:  (584248, 6)\n",
      "trackVars_test:  (64917, 6)\n",
      "y_train:  (584248, 6)\n",
      "y_test (64917, 6)\n"
     ]
    }
   ],
   "source": [
    "print('startGridU_train: ', startGridU_train.shape)\n",
    "print('startGridV_train: ', startGridV_train.shape)\n",
    "print('startGridW_train: ', startGridW_train.shape)\n",
    "print('startGridU_test: ', startGridU_test.shape)\n",
    "print('startGridV_test: ', startGridV_test.shape)\n",
    "print('startGridW_test: ', startGridW_test.shape)\n",
    "   \n",
    "print('endGridU_train: ', endGridU_train.shape)    \n",
    "print('endGridV_train: ', endGridV_train.shape)\n",
    "print('endGridW_train: ', endGridW_train.shape)\n",
    "print('endGridU_test: ', endGridU_test.shape)     \n",
    "print('endGridV_test: ', endGridV_test.shape)     \n",
    "print('endGridW_test: ', endGridW_test.shape) \n",
    "    \n",
    "print('trackVars_train: ', trackVars_train.shape)    \n",
    "print('trackVars_test: ', trackVars_test.shape)  \n",
    "\n",
    "print('y_train: ', y_train.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c82c165f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meanStartU:  0.000308594\n",
      "meanStartV:  0.0002996729\n",
      "meanStartW:  0.00035025433\n",
      "varStartU:  1.7085616e-06\n",
      "varStartV:  1.6024245e-06\n",
      "varStartW:  2.4753515e-06\n",
      "meanEndU:  0.00016634335\n",
      "meanEndV:  0.0001585949\n",
      "meanEndW:  0.00018217393\n",
      "varEndU:  8.492248e-07\n",
      "varEndV:  7.424318e-07\n",
      "varEndW:  1.1545056e-06\n"
     ]
    }
   ],
   "source": [
    "# Work out the mean and variance\n",
    "\n",
    "meanStartU = np.mean(startGridU_train)\n",
    "meanStartV = np.mean(startGridV_train)\n",
    "meanStartW = np.mean(startGridW_train)\n",
    "\n",
    "meanEndU = np.mean(endGridU_train)\n",
    "meanEndV = np.mean(endGridV_train)\n",
    "meanEndW = np.mean(endGridW_train)\n",
    "\n",
    "varStartU = np.var(startGridU_train)\n",
    "varStartV = np.var(startGridV_train)\n",
    "varStartW = np.var(startGridW_train)\n",
    "\n",
    "varEndU = np.var(endGridU_train)\n",
    "varEndV = np.var(endGridV_train)\n",
    "varEndW = np.var(endGridW_train)\n",
    "\n",
    "print('meanStartU: ', meanStartU)\n",
    "print('meanStartV: ', meanStartV)\n",
    "print('meanStartW: ', meanStartW)\n",
    "\n",
    "print('varStartU: ', varStartU)\n",
    "print('varStartV: ', varStartV)\n",
    "print('varStartW: ', varStartW)\n",
    "\n",
    "print('meanEndU: ', meanEndU)\n",
    "print('meanEndV: ', meanEndV)\n",
    "print('meanEndW: ', meanEndW)\n",
    "\n",
    "print('varEndU: ', varEndU)\n",
    "print('varEndV: ', varEndV)\n",
    "print('varEndW: ', varEndW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0edf463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ivysaurusCNN = IvysaurusModel.IvysaurusIChooseYou(dimensions, nClasses, nTrackVars, meanStartU, varStartU, meanStartV, varStartV, meanStartW, varStartW, meanEndU, varEndU, meanEndV, varEndV, meanEndW, varEndW)\n",
    "#ivysaurusCNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7110dfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimiser and compile the model\n",
    "optimiser = optimizers.legacy.Adam(learning_rate=learningRate)\n",
    "ivysaurusCNN.compile(loss='categorical_crossentropy', optimizer=optimiser, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "def45a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]]\n",
      "{0: 2.19742975935492, 1: 1.0, 2: 1.1791630045297816, 3: 2.222916135610502, 4: 1.0643842304406201, 5: 0}\n"
     ]
    }
   ],
   "source": [
    "# Create class weights\n",
    "\n",
    "print(y_test)\n",
    "indexVector = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # muons = 0, protons = 1, pions = 2, electrons = 3, photons = 4, other = 5\n",
    "\n",
    "nMuons = np.count_nonzero(indexVector == 0)    \n",
    "nProtons = np.count_nonzero(indexVector == 1)  \n",
    "nPions = np.count_nonzero(indexVector == 2)  \n",
    "nElectrons = np.count_nonzero(indexVector == 3)  \n",
    "nPhotons = np.count_nonzero(indexVector == 4)  \n",
    "nOther = np.count_nonzero(indexVector == 5)  \n",
    "\n",
    "\n",
    "# Normalise to largest\n",
    "maxParticle = max(nMuons, nProtons, nPions, nElectrons, nPhotons)\n",
    "\n",
    "classWeights = {0: maxParticle/nMuons, 1: maxParticle/nProtons, 2: maxParticle/nPions, 3: maxParticle/nElectrons, 4: maxParticle/nPhotons, 5:0}\n",
    "\n",
    "print(classWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "400ec1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9129/9129 [==============================] - 544s 60ms/step - loss: 1.2170 - accuracy: 0.6361 - val_loss: 0.8932 - val_accuracy: 0.7001 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "9129/9129 [==============================] - 653s 72ms/step - loss: 0.9591 - accuracy: 0.7175 - val_loss: 0.8282 - val_accuracy: 0.7398 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "9129/9129 [==============================] - 637s 70ms/step - loss: 0.8761 - accuracy: 0.7407 - val_loss: 0.8220 - val_accuracy: 0.7488 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "9129/9129 [==============================] - 742s 81ms/step - loss: 0.8262 - accuracy: 0.7552 - val_loss: 0.7936 - val_accuracy: 0.7508 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "9129/9129 [==============================] - 674s 74ms/step - loss: 0.7901 - accuracy: 0.7664 - val_loss: 0.7769 - val_accuracy: 0.7689 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "9129/9129 [==============================] - 642s 70ms/step - loss: 0.7640 - accuracy: 0.7748 - val_loss: 0.7675 - val_accuracy: 0.7761 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "9129/9129 [==============================] - 1029s 113ms/step - loss: 0.7442 - accuracy: 0.7810 - val_loss: 0.7251 - val_accuracy: 0.7857 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "5710/9129 [=================>............] - ETA: 6:44 - loss: 0.7296 - accuracy: 0.7846"
     ]
    }
   ],
   "source": [
    "# Fit that model!\n",
    "\n",
    "# Reduce the learning rate by a factor of ten when required\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-6, verbose=1)\n",
    "history = ivysaurusCNN.fit([startGridU_train, endGridU_train, startGridV_train, endGridV_train, startGridW_train, endGridW_train, trackVars_train], y_train, \n",
    "    batch_size = batchSize, validation_data=([startGridU_test, endGridU_test, startGridV_test, endGridV_test, startGridW_test, endGridW_test, trackVars_test], y_test), \n",
    "    shuffle=True, epochs=nEpochs, class_weight=classWeights, callbacks=[reduce_lr]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d2af61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate training\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd0356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the network to predict the category of the test sample\n",
    "\n",
    "y_pred = ivysaurusCNN.predict([startGridU_test, endGridU_test, startGridV_test, endGridV_test, startGridW_test, endGridW_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8fe6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrectIndicies = []\n",
    "\n",
    "for i in range (y_pred.shape[0]) :\n",
    "    prediction = np.argmax(y_pred[i])\n",
    "    truth = np.argmax(y_test[i])\n",
    "    if (prediction != truth) :\n",
    "        incorrectIndicies.append([i, prediction, truth])\n",
    "    \n",
    "print(incorrectIndicies)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ee05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the confusion matrix\n",
    "\n",
    "confMatrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "\n",
    "trueSums = np.sum(confMatrix, axis=1)\n",
    "predSums = np.sum(confMatrix, axis=0)\n",
    "\n",
    "print('trueSums: ', trueSums)\n",
    "print('predSums: ', predSums)\n",
    "\n",
    "trueNormalised = np.zeros(shape=(nClasses, nClasses))\n",
    "predNormalised = np.zeros(shape=(nClasses, nClasses))\n",
    "\n",
    "for trueIndex in range(nClasses) : \n",
    "    for predIndex in range(nClasses) :\n",
    "        nEntries = confMatrix[trueIndex][predIndex]\n",
    "        if trueSums[trueIndex] > 0 :\n",
    "            trueNormalised[trueIndex][predIndex] = float(nEntries) / float(trueSums[trueIndex])\n",
    "        if predSums[predIndex] > 0 :\n",
    "            predNormalised[trueIndex][predIndex] = float(nEntries) / float(predSums[predIndex])\n",
    "\n",
    "displayTrueNorm = ConfusionMatrixDisplay(confusion_matrix=trueNormalised, display_labels=[\"Muon\", \"Proton\", \"Pion\", \"Electron\", \"Photon\", \"Other\"])\n",
    "displayTrueNorm.plot()\n",
    "\n",
    "displayPredNorm = ConfusionMatrixDisplay(confusion_matrix=predNormalised, display_labels=[\"Muon\", \"Proton\", \"Pion\", \"Electron\", \"Photon\", \"Other\"])\n",
    "displayPredNorm.plot()\n",
    "\n",
    "print(confMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a7f19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "\n",
    "falsePositive = dict()\n",
    "bkgRejection = dict()\n",
    "truePositive = dict()\n",
    "roc = dict()\n",
    "\n",
    "for i in range(nClasses):\n",
    "    falsePositive[i], truePositive[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    bkgRejection[i] = 1 - falsePositive[i]\n",
    "    roc[i] = sklearn.metrics.auc(falsePositive[i], bkgRejection[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "\n",
    "rocCurveTitles = [\"Muon\", \"Proton\", \"Pion\", \"Electron\", \"Photon\", \"Other\"]\n",
    "\n",
    "for i in range(nClasses):\n",
    "    plt.figure()\n",
    "    plt.plot(truePositive[i], bkgRejection[i], label='ROC curve (area = %0.2f)' % roc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xticks(np.arange(0, 1, 0.1))\n",
    "    plt.yticks(np.arange(0, 1, 0.1))\n",
    "    plt.xlabel('Efficiency')\n",
    "    plt.ylabel('BG Rejection')\n",
    "    plt.title(rocCurveTitles[i])\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604055b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "particleColors = ('b', 'g', 'k', 'r', 'tab:orange', 'tab:gray')\n",
    "histTitles = ('CNN Muon Score', 'CCN Proton Score', 'CNN Pion Score', 'CNN Electron Score', 'CNN Photon Score', 'CNN Other Score')\n",
    "\n",
    "for i in range(nClasses) :\n",
    "    for j in range(nClasses) :\n",
    "        nTrueParticles = trueSums[j]\n",
    "        weights = np.full(nTrueParticles, 1.0/nTrueParticles)\n",
    "        plt.hist(y_pred[y_test[:,j] == 1][:,i], bins=40, weights=weights, color=particleColors[j], histtype='step')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.xlabel(histTitles[i])\n",
    "        plt.ylabel('Proportion of Tracks')\n",
    "        plt.legend(['Muon', 'Proton', 'Pion', 'Electron', 'Photon', 'Other'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47c0b37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
